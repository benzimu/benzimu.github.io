[{"categories":["Tornado 源码解析"],"content":"tornado multiple processes tornado 实现了多进程的执行模式。使用 tornado 多进程启动服务时，IOLoop 的初始化（IOLoop.current()）操作必须在 fork 子进程之后执行。且在多进程模式下无法使用 debug 模式，因为实现 debug 模式的 autoreload.py 在 tornado.web.Application 初始化时就已经实例化了 IOLoop。tornado 使用多进程的方式有下面两种： # 方式一 app = tornado.web.Application(urls) sockets = tornado.netutil.bind_sockets(port, address) tornado.process.fork_processes(0) # # 默认为系统CPU核数 http_server = tornado.httpserver.HTTPServer(app) http_server.add_sockets(sockets) tornado.ioloop.IOLoop.current().start() # 方式二 app = tornado.web.Application(urls) server = tornado.httpserver.HTTPServer(app) server.bind(port, address) server.start(0) # 默认为系统CPU核数 tornado.ioloop.IOLoop.current().start() 以方式一为例分析多进程实现源码。tornado.netutil.bind_sockets() 详解参考：tornado_netutil#bind_sockets() ","date":"2017-11-10","objectID":"/tornado_multi_processes/:1:0","tags":["Tornado"],"title":"tornado 多进程实现解析","uri":"/tornado_multi_processes/"},{"categories":["Tornado 源码解析"],"content":"tornado.process.fork_processes() def fork_processes(num_processes, max_restarts=100): global _task_id assert _task_id is None # 当传入的num_processes为None或者小于等于0时，默认使用系统CPU核数 if num_processes is None or num_processes \u003c= 0: num_processes = cpu_count() # 如果IOLoop已经实例化，则抛出异常 if ioloop.IOLoop.initialized(): raise RuntimeError(\"Cannot run in multiple processes: IOLoop instance \" \"has already been initialized. You cannot call \" \"IOLoop.instance() before calling start_processes()\") gen_log.info(\"Starting %d processes\", num_processes) # 用于保存子进程PID children = {} # fork子进程的内部函数 def start_child(i): # 一次调用，两次返回 pid = os.fork() # 子进程运行 if pid == 0: # child process _reseed_random() global _task_id _task_id = i return i # 父进程运行 else: children[pid] = i return None # 根据num_processes生成对应数量的子进程 for i in range(num_processes): id = start_child(i) # 此时父进程还需要执行下面的操作，所以fork时必须父进程先执行，否者直接返回 if id is not None: return id num_restarts = 0 # 遍历所有子进程 while children: try: # 等待子进程执行，阻塞，返回子进程的pid、子进程退出时的状态信息，0表示子进程没有出现异常 pid, status = os.wait() except OSError as e: if errno_from_exception(e) == errno.EINTR: continue raise if pid not in children: continue # 将退出的进程从dict中移除 id = children.pop(pid) # 处理子进程退出状态 if os.WIFSIGNALED(status): gen_log.warning(\"child %d (pid %d) killed by signal %d, restarting\", id, pid, os.WTERMSIG(status)) elif os.WEXITSTATUS(status) != 0: gen_log.warning(\"child %d (pid %d) exited with status %d, restarting\", id, pid, os.WEXITSTATUS(status)) else: gen_log.info(\"child %d (pid %d) exited normally\", id, pid) continue num_restarts += 1 # 如果重启次数操作最大次数，则抛出异常 if num_restarts \u003e max_restarts: raise RuntimeError(\"Too many child restarts, giving up\") # 重启子进程 new_id = start_child(id) if new_id is not None: return new_id sys.exit(0) os.fork() 函数调用有两次返回，当返回值为 0 时，表示此时为子进程运行中，当值不为 0 时，表示父进程运行中。因为父进程需要继续执行下面的代码，所以 fork() 子进程返回时必须先执行父进程，即返回值不为 0。调用 fork() 之后先执行哪个进程的是由 Linux 下专有文件 /proc/sys/kernel/sched_child_runs_first 的值来确定的(值为 0 父进程先执行，非 0 子进程先执行)。 当子进程全部 fork() 完成之后，父进程（main 函数）会调用 os.wait() 阻塞住，等待子进程执行。此时，所有的子进程会执行各自内存空间的代码段。子进程由于完全复用父进程的代码段，则都会继续执行方式一中 tornado.process.fork_processes(0) 之后的代码。只有当所有的子进程都正常退出或者重启次数超过限制之后，父进程才会退出（sys.exit(0)）。 http_server.add_sockets(sockets) 方法会完成服务器 socket 的监听，即 accept()，并将其回调函数注册到 IOLoop，已完成客户端与服务端的通信。详解请参考：tornado_httpserver。 方式二的 server.start(0) 封装了子进程的fork操作，原理与方式一一样。 ","date":"2017-11-10","objectID":"/tornado_multi_processes/:1:1","tags":["Tornado"],"title":"tornado 多进程实现解析","uri":"/tornado_multi_processes/"},{"categories":["Tornado 源码解析"],"content":"多进程模式下，如何避免同一个请求不被多次执行呢？ tornado 多进程的处理流程实现创建服务器 socket，然后在 fork 子进程，这样所有的子进程都监听同一个文件描述符，即同一个 socket。 当连接过来时，所有的子进程都会收到可读事件，这是所有的子进程都会调到 accept_handler 回调函数，尝试建立连接。 一旦其中的一个子进程成功的建立了连接，当其他子进程在尝试建立连接时就会触发EWOULDBLOCK或者EAGAIN错误，这时回调函数判断是这个错误则不做处理。详解参考：tornado_netutil#add_accept_handler()。 当成功建立连接的子进程还在处理这个连接的时候有过来一个连接，则由另外一个子进程处理这个连接。 tornado 就是通过这样一种机制，利用多进程提升效率，由于一个连接只能有一个子进程成功创建，同一个请求也就不会被多个子进程处理。 IOLoop 为单例、多进程模式。 ","date":"2017-11-10","objectID":"/tornado_multi_processes/:1:2","tags":["Tornado"],"title":"tornado 多进程实现解析","uri":"/tornado_multi_processes/"},{"categories":["Tornado 源码解析"],"content":"tornado concurrent 实现解析 用于处理线程和 Futures 的工具。Futures 是 python3.2 中 concurrent.futures 包引入的并发编程模式。在本模块中，定义了一个兼容的 Future 类，它被设计用于协同工作，还有一些用于与 concurrent.futures 包交互的实用函数。 Future 的设计目标是作为协程（coroutine）和 IOLoop 的媒介，从而将协程和 IOLoop 关联起来。 Future 是异步操作结果的占位符，用于等待结果返回。通常作为函数 IOLoop.add_future() 的参数或 gen.coroutine 协程中 yield 的返回值。 等到结果返回时，外部可以通过调用 set_result() 设置真正的结果，将结果保存在 Future 内存中，然后调用所有回调函数，恢复协程的执行，最后通过 result() 获取结果。 Future 类通过 self._done 的值来判断本次 Future 操作是否结束，默认为 False，当调用 set_result() 设置结果、或者调用 set_exc_info() 设置异常时会调用 _set_done() 修改其值，即表示本次操作已经完成。 ","date":"2017-11-10","objectID":"/tornado_concurrent/:1:0","tags":["Tornado"],"title":"tornado concurrent 实现解析","uri":"/tornado_concurrent/"},{"categories":["Tornado 源码解析"],"content":"tornado.concurrent.Future.set_result() def set_result(self, result): # 将结果保存到 self._result self._result = result # 修改 self._done，并调用所有回调函数 self._set_done() ","date":"2017-11-10","objectID":"/tornado_concurrent/:1:1","tags":["Tornado"],"title":"tornado concurrent 实现解析","uri":"/tornado_concurrent/"},{"categories":["Tornado 源码解析"],"content":"tornado.concurrent.Future._set_done() def _set_done(self): # 修改 self._done 值，表示本次操作已完成 self._done = True # 循环执行 self._callbacks 中的回调函数，通过 add_done_callback() 定义 for cb in self._callbacks: try: cb(self) except Exception: app_log.exception('Exception in callback %r for %r', cb, self) self._callbacks = None ","date":"2017-11-10","objectID":"/tornado_concurrent/:1:2","tags":["Tornado"],"title":"tornado concurrent 实现解析","uri":"/tornado_concurrent/"},{"categories":["Tornado 源码解析"],"content":"tornado.concurrent.Future.add_done_callback() def add_done_callback(self, fn): # 添加本次 Future 操作完成时的回调函数，如果 Future 还没结束，则将回调函数加入 # self._callbacks，以便结束时调用，如果已经结束，则直接运行回调函数 if self._done: fn(self) else: self._callbacks.append(fn) ","date":"2017-11-10","objectID":"/tornado_concurrent/:1:3","tags":["Tornado"],"title":"tornado concurrent 实现解析","uri":"/tornado_concurrent/"},{"categories":["Tornado 源码解析"],"content":"tornado.concurrent.Future.result() def result(self, timeout=None): # 清理日志 self._clear_tb_log() # 判断 self._result 结果是否为None，通过 set_result() 设置 if self._result is not None: return self._result # 判断是否有异常信息，通过 set_exc_info() 设置 if self._exc_info is not None: try: raise_exc_info(self._exc_info) finally: self = None # 检查是否结束 self._check_done() return self._result ","date":"2017-11-10","objectID":"/tornado_concurrent/:1:4","tags":["Tornado"],"title":"tornado concurrent 实现解析","uri":"/tornado_concurrent/"},{"categories":["Tornado 源码解析"],"content":"tornado.concurrent.chain_future() def chain_future(a, b): # 将两个Future对象关联在一起，一个完成，另一个也完成 # “a”的结果（成功或失败）将被复制到“b”，除非在“a”结束之前，“b”已经完成或被取消。 def copy(future): assert future is a # 如果b已经完成或者取消，则直接返回 if b.done(): return if (isinstance(a, TracebackFuture) and isinstance(b, TracebackFuture) and a.exc_info() is not None): b.set_exc_info(a.exc_info()) elif a.exception() is not None: b.set_exception(a.exception()) else: b.set_result(a.result()) # 将 copy()添加到 a 的回调列表中 a.add_done_callback(copy) 首先会调用 a.add_done_callback(copy)，若 a 已经完成则直接运行 copy 函数，否则加入到回调列表中等到 a 完成时再运行。copy 函数将两个 Future 对象联系到了一起，用作结果返回、超时处理。 ","date":"2017-11-10","objectID":"/tornado_concurrent/:1:5","tags":["Tornado"],"title":"tornado concurrent 实现解析","uri":"/tornado_concurrent/"},{"categories":["Tornado 源码解析"],"content":"tornado gen 实现解析 tornado.gen是一个基于生成器的接口，可以更容易地在异步环境中工作。使用gen模块的代码在技术上是异步的，但它被写成一个单独的生成器，而不是另外的函数集合。 ","date":"2017-11-10","objectID":"/tornado_gen/:1:0","tags":["Tornado"],"title":"tornado gen 实现解析","uri":"/tornado_gen/"},{"categories":["Tornado 源码解析"],"content":"tornado.gen.with_timeout() def with_timeout(timeout, future, io_loop=None, quiet_exceptions=()): # 在超时时间内封装Future对象 # 如果传入的future在超时之前没有完成，则引发TimeoutError，可以通过 # .IOLoop.add_timeout（即datetime.timedelta或者相对于.IOLoop.time的绝对 # 时间）允许的任何形式来指定。 # 如果封装的Future在超时之后失败，则将记录该异常，除非它是“quiet_exceptions” # （可能是一个异常类型或一系列类型）中包含的类型。 # 将一个yielded对象转换为一个Future future = convert_yielded(future) # 初始化一个新的Future对象 result = Future() # 将新的Future对象与待处理的future关联，用于超时处理、结果处理 chain_future(future, result) if io_loop is None: io_loop = IOLoop.current() # future超时处理函数 def error_callback(future): try: future.result() except Exception as e: if not isinstance(e, quiet_exceptions): app_log.error(\"Exception in Future %r after timeout\", future, exc_info=True) # IOLoop超时回调函数 def timeout_callback(): result.set_exception(TimeoutError(\"Timeout\")) # In case the wrapped future goes on to fail, log it. future.add_done_callback(error_callback) # 添加超时事件到IOLoop timeout_handle = io_loop.add_timeout( timeout, timeout_callback) # 根据future不同类型，分别处理删除IOLoop中future的超时回调事件 if isinstance(future, Future): # We know this future will resolve on the IOLoop, so we don't # need the extra thread-safety of IOLoop.add_future (and we also # don't care about StackContext here. future.add_done_callback( lambda future: io_loop.remove_timeout(timeout_handle)) else: # concurrent.futures.Futures may resolve on any thread, so we # need to route them back to the IOLoop. io_loop.add_future( future, lambda future: io_loop.remove_timeout(timeout_handle)) return result 首先会初始化一个 Future 对象，用于获取结果，即 result。 然后调用 chain_future 将 future 与 result 对象绑定，参考详解：tornado_concurrent#chain_future()。 接着会注册超时事件到 IOLoop，具体参考详解：tornado_ioloop_PeriodicCallback#add_timeout()。 如果 timeout 超时了，则 IOLoop 会调用 timeout_callback，然后 result 调用 set_exception 抛出异常，并终止 Future，即设置 self._done 为 True；future 也同样抛出异常，会将异常写入日志中。如果在 timeout 超时之前 future 操作成功完成，则会将其返回数据写到 result 中，并删除注册到 IOLoop 中的超时回调事件。 ","date":"2017-11-10","objectID":"/tornado_gen/:1:1","tags":["Tornado"],"title":"tornado gen 实现解析","uri":"/tornado_gen/"},{"categories":["Tornado 源码解析"],"content":"tornado 定时器 PeriodicCallback tornado.ioloop.PeriodicCallback 是 tornado 实现的定时器。 class Application(tornado.web.Application): def __init__(self): handlers = [ (r\"/\", HomeHandler), ] settings = dict( debug=True, ) super(Application, self).__init__(handlers, **settings) 当创建 tornado Application 时，如果设置 “debug=True”，tornado 会在源程序修改后自动编译，而不需要我们手动重启。 ","date":"2017-11-10","objectID":"/tornado_ioloop_periodiccallback/:1:0","tags":["Tornado"],"title":"tornado 定时器 PeriodicCallback 实现解析","uri":"/tornado_ioloop_periodiccallback/"},{"categories":["Tornado 源码解析"],"content":"tornado.web.Application.__init__() def __init__(self, handlers=None, default_host=None, transforms=None, **settings): #####省略##### # 当设置了debug=True时，tornado会默认设置autoreload=True if self.settings.get('debug'): self.settings.setdefault('autoreload', True) self.settings.setdefault('compiled_template_cache', False) self.settings.setdefault('static_hash_cache', False) self.settings.setdefault('serve_traceback', True) #####省略##### # 判断是否设置了autoreload，如果设置了就会调用autoreload.start()， # 启动自动重载功能 if self.settings.get('autoreload'): from tornado import autoreload autoreload.start() ","date":"2017-11-10","objectID":"/tornado_ioloop_periodiccallback/:1:1","tags":["Tornado"],"title":"tornado 定时器 PeriodicCallback 实现解析","uri":"/tornado_ioloop_periodiccallback/"},{"categories":["Tornado 源码解析"],"content":"tornado.autoreload.start() def start(io_loop=None, check_time=500): # 获取IOLoop实例 io_loop = io_loop or ioloop.IOLoop.current() # 如果当前IOLoop实例是弱引用的则直接返回 if io_loop in _io_loops: return _io_loops[io_loop] = True if len(_io_loops) \u003e 1: gen_log.warning(\"tornado.autoreload started more than once in the same process\") modify_times = {} # 生成回调函数 callback = functools.partial(_reload_on_update, modify_times) # 初始化tornado.PeriodicCallback定时器 scheduler = ioloop.PeriodicCallback(callback, check_time, io_loop=io_loop) # 开始执行定时器 scheduler.start() ","date":"2017-11-10","objectID":"/tornado_ioloop_periodiccallback/:1:2","tags":["Tornado"],"title":"tornado 定时器 PeriodicCallback 实现解析","uri":"/tornado_ioloop_periodiccallback/"},{"categories":["Tornado 源码解析"],"content":"tornado.ioloop.PeriodicCallback.start() def start(self): # 设置定时器运行中 self._running = True # 初始化下次的超时事件的最后期限 self._next_timeout = self.io_loop.time() # 关键方法，对下次超时事件的封装 self._schedule_next() ","date":"2017-11-10","objectID":"/tornado_ioloop_periodiccallback/:1:3","tags":["Tornado"],"title":"tornado 定时器 PeriodicCallback 实现解析","uri":"/tornado_ioloop_periodiccallback/"},{"categories":["Tornado 源码解析"],"content":"tornado.ioloop.PeriodicCallback._schedule_next() def _schedule_next(self): if self._running: # 获取当前时间 current_time = self.io_loop.time() # 如果当前时间已经超过了超时事件的最后期限，则重新设置超时时间 if self._next_timeout \u003c= current_time: # self.callback_time为autoreload.start()方法中初始化定时器时传入的 # check_time，即500毫秒 callback_time_sec = self.callback_time / 1000.0 self._next_timeout += (math.floor((current_time - self._next_timeout) / callback_time_sec) + 1) * callback_time_sec # 关键所在，添加超时事件，将self._run作为超时后的回调函数 self._timeout = self.io_loop.add_timeout(self._next_timeout, self._run) ","date":"2017-11-10","objectID":"/tornado_ioloop_periodiccallback/:1:4","tags":["Tornado"],"title":"tornado 定时器 PeriodicCallback 实现解析","uri":"/tornado_ioloop_periodiccallback/"},{"categories":["Tornado 源码解析"],"content":"tornado.ioloop.PeriodicCallback._run() def _run(self): # 判断定时器是否还在运行 if not self._running: return try: # 调用autoreload.start()方法中初始化时传入的超时回调函数 return self.callback() except Exception: self.io_loop.handle_callback_exception(self.callback) finally: # 无论如何，都会再次调用self._schedule_next()再次添加超时事件到IOLoop中， # 这样就会一直循环，即定时器操作 self._schedule_next() 在 PeriodicCallback._schedule_next() 的最后一行执行的添加超时事件就会被 IOLoop 下次循环中。 ","date":"2017-11-10","objectID":"/tornado_ioloop_periodiccallback/:1:5","tags":["Tornado"],"title":"tornado 定时器 PeriodicCallback 实现解析","uri":"/tornado_ioloop_periodiccallback/"},{"categories":["Tornado 源码解析"],"content":"tornado.ioloop.IOLoop.add_timeout() def add_timeout(self, deadline, callback, *args, **kwargs): # 判断超时事件的最后期限deadline是否为实数，一般为实数 if isinstance(deadline, numbers.Real): return self.call_at(deadline, callback, *args, **kwargs) # 在使用call_later()方法设置超时事件时deadline为datetime.timedelta类型 elif isinstance(deadline, datetime.timedelta): return self.call_at(self.time() + timedelta_to_seconds(deadline), callback, *args, **kwargs) else: raise TypeError(\"Unsupported deadline %r\" % deadline) tornado 规定继承至 IOLoop 的子类必须实现 add_timeout() 或者 call_at() 方法，因为默认实现只是相互调用，而没有实质作用。tornado.ioloop.PollIOLoop 则实现了 call_at()。 ","date":"2017-11-10","objectID":"/tornado_ioloop_periodiccallback/:1:6","tags":["Tornado"],"title":"tornado 定时器 PeriodicCallback 实现解析","uri":"/tornado_ioloop_periodiccallback/"},{"categories":["Tornado 源码解析"],"content":"tornado.ioloop.PollIOLoop.call_at() def call_at(self, deadline, callback, *args, **kwargs): # 初始化_Timeout对象，该对象是对超时事件的封装，同时重写了__lt__()、__le__() # 两个方法，实现了_Timeout的大小比较。 timeout = _Timeout( deadline, functools.partial(stack_context.wrap(callback), *args, **kwargs), self) # 通过堆排序添加timeout到self._timeouts列表中，因此确定了self._timeouts[0] # 总是最小的，即最后期限deadline最小的，当最后期限相同时则为最先添加 # 到self._timeouts的 heapq.heappush(self._timeouts, timeout) return timeout 执行该函数之后 timeouts 就会被添加到 self._timeouts 中，当 tornado IOLoop 的 epoll.poll() 函数再次醒来时，则会重新迭代，然后调用 self._timeouts，进行相关判断处理。详解参考：tornado_ioloop#start() ","date":"2017-11-10","objectID":"/tornado_ioloop_periodiccallback/:1:7","tags":["Tornado"],"title":"tornado 定时器 PeriodicCallback 实现解析","uri":"/tornado_ioloop_periodiccallback/"},{"categories":["Tornado 源码解析"],"content":"tornado iostream 实现解析 封装了对 socket fd 底层数据的读取、写入操作，针对不同的情况实现了几种不同的读取方式。 ","date":"2017-11-06","objectID":"/tornado_iostream/:1:0","tags":["Tornado"],"title":"tornado iostream 实现解析","uri":"/tornado_iostream/"},{"categories":["Tornado 源码解析"],"content":"tornado.iostream.BaseIOStream.read_until_regex() def read_until_regex(self, regex, callback=None, max_bytes=None): # 设置读取完成后的回调函数 future = self._set_read_callback(callback) # 编译正则表达式，并保存到self._read_regex self._read_regex = re.compile(regex) # 保存最大读取数据长度到self._read_max_bytes self._read_max_bytes = max_bytes try: self._try_inline_read() except UnsatisfiableReadError as e: # Handle this the same way as in _handle_events. gen_log.info(\"Unsatisfiable read, closing connection: %s\" % e) self.close(exc_info=True) return future except: if future is not None: # Ensure that the future doesn't log an error because its # failure was never examined. future.add_done_callback(lambda f: f.exception()) raise return future 通过正则表达式匹配客户端发来的数据，http协议规定了数据结构，每行数据后面都会有一个 CRLF，而请求行与请求头数据结尾也会有一个 CRLF，即请求头数据后面有两个 CRLF，请求体也是如此。 CRLF 即为回车（Carriage-Return，CR，\\r）、换行（Line-Feed，LF，\\n）。Windows 下 CRLF 表示：\\r\\n；Unix 下 CRLF 表示：\\n。 tornado.http1connection.HTTP1Connection._read_message() 方法调用本方法传入的 regex 参数为 “\\r?\\n\\r?\\n”，刚好兼容了 Windows 和 Unix。 ","date":"2017-11-06","objectID":"/tornado_iostream/:1:1","tags":["Tornado"],"title":"tornado iostream 实现解析","uri":"/tornado_iostream/"},{"categories":["Tornado 源码解析"],"content":"tornado.iostream.BaseIOStream._set_read_callback() def _set_read_callback(self, callback): assert self._read_callback is None, \"Already reading\" assert self._read_future is None, \"Already reading\" if callback is not None: self._read_callback = stack_context.wrap(callback) else: self._read_future = TracebackFuture() return self._read_future 通过 read_until_regex 方法读取请求数据时，是没有 callback 的，即 callback 为 None，所以_set_read_callback 会返回一个 Future 对象实例，用于返回异步执行结果。 ","date":"2017-11-06","objectID":"/tornado_iostream/:1:2","tags":["Tornado"],"title":"tornado iostream 实现解析","uri":"/tornado_iostream/"},{"categories":["Tornado 源码解析"],"content":"tornado.iostream.BaseIOStream._try_inline_read() def _try_inline_read(self): # 尝试从缓存数据中完成当前读操作。 # 如果此次读操作能在无阻塞的情况下完成，则在下次IOLoop迭代中执行读回调函数， # 否则为此次读事件在套接字上启动监听 # 查看是否从前一次的读操作中获取到了数据 # 第一部分 self._run_streaming_callback() pos = self._find_read_pos() if pos is not None: self._read_from_buffer(pos) return # 第二部分 self._check_closed() try: pos = self._read_to_buffer_loop() except Exception: # If there was an in _read_to_buffer, we called close() already, # but couldn't run the close callback because of _pending_callbacks. # Before we escape from this function, run the close callback if # applicable. self._maybe_run_close_callback() raise if pos is not None: self._read_from_buffer(pos) return # 第三部分 # We couldn't satisfy the read inline, so either close the stream # or listen for new data. if self.closed(): self._maybe_run_close_callback() else: self._add_io_state(ioloop.IOLoop.READ) 方法可以分为三部分： 第一部分 首先会去检测前一次是否将数据读取到了缓存，即通过 self._find_read_pos() 获取到的 pos 是否为 None，如果不为 None，则表示已经读取数据完成（读取到足够大小的数据：max_bytes 参数、正则表达式匹配成功：regex 参数，或者遇到指定的分隔符：read_until() 方法中的 delimiter 参数），然后调用 self._read_from_buffer(pos) 将_read_future 加入 IOLoop； 第二部分 调用 self._read_to_buffer_loop() 循环读取请求数据，方法中封装了第一部分的部分操作，接下来与第一部分操作一致； 第三部分 判断该stream连接是否断开，如果已经断开调用关闭回调函数，否则将该连接再次放到 IOLoop 中，继续读取数据。 ","date":"2017-11-06","objectID":"/tornado_iostream/:1:3","tags":["Tornado"],"title":"tornado iostream 实现解析","uri":"/tornado_iostream/"},{"categories":["Tornado 源码解析"],"content":"tornado.iostream.BaseIOStream._find_read_pos() def _find_read_pos(self): # 试图在读取缓冲区中找到满足当前待读取的位置 # 如果能够满足当前读取，则返回缓冲区中的位置;如果不能，则返回None。 if (self._read_bytes is not None and (self._read_buffer_size \u003e= self._read_bytes or (self._read_partial and self._read_buffer_size \u003e 0))): num_bytes = min(self._read_bytes, self._read_buffer_size) return num_bytes elif self._read_delimiter is not None: # Multi-byte delimiters (e.g. '\\r\\n') may straddle two # chunks in the read buffer, so we can't easily find them # without collapsing the buffer. However, since protocols # using delimited reads (as opposed to reads of a known # length) tend to be \"line\" oriented, the delimiter is likely # to be in the first few chunks. Merge the buffer gradually # since large merges are relatively expensive and get undone in # _consume(). if self._read_buffer: loc = self._read_buffer.find(self._read_delimiter, self._read_buffer_pos) if loc != -1: loc -= self._read_buffer_pos delimiter_len = len(self._read_delimiter) self._check_max_bytes(self._read_delimiter, loc + delimiter_len) return loc + delimiter_len self._check_max_bytes(self._read_delimiter, self._read_buffer_size) elif self._read_regex is not None: # self._read_buffer在_read_to_buffer方法中定义 if self._read_buffer: # 在已读取的数据中从上一次的位置开始匹配正则，self._read_buffer_pos在 # _consume方法中定义 m = self._read_regex.search(self._read_buffer, self._read_buffer_pos) # 匹配成功 if m is not None: # 获取本次读取的数据大小 loc = m.end() - self._read_buffer_pos # 判断本次读取的数据是否超过了最大读取数据量，如果是则 # 报错UnsatisfiableReadError self._check_max_bytes(self._read_regex, loc) return loc # 如果没有匹配到正则表达式，则检查读取的数据量是否超过了最大读取数据量 # self._read_buffer_size在_read_to_buffer方法中定义 self._check_max_bytes(self._read_regex, self._read_buffer_size) return None 在 read_until_regex() 方法中，self._read_regex 是存在的，self._read_delimiter 是针对 read_until() 方法的操作。在此方法中可知，传入 read_until_regex() 的 max_bytes 必须要大于 self.read_chunk_size（socket.recv 每次循环接收的数据量），否则会直接报错。 ","date":"2017-11-06","objectID":"/tornado_iostream/:1:4","tags":["Tornado"],"title":"tornado iostream 实现解析","uri":"/tornado_iostream/"},{"categories":["Tornado 源码解析"],"content":"tornado.iostream.BaseIOStream._read_to_buffer_loop() def _read_to_buffer_loop(self): # This method is called from _handle_read and _try_inline_read. try: # 根据不同的方法调用获取对应的目标数据量 if self._read_bytes is not None: target_bytes = self._read_bytes elif self._read_max_bytes is not None: target_bytes = self._read_max_bytes elif self.reading(): # 对于没有max_bytes参数的read_until或者read_until_close，应在扫描分 # 隔符之前尽可能多地进行读取。 target_bytes = None else: target_bytes = 0 next_find_pos = 0 # 假装有一个挂起的回调，以便_read_to_buffer中的EOF不会触发立即关闭回调。 # 在这个方法（_try_inline_read）的最后，我们要么通过_read_from_buffer # 建立一个真正的等待回调，要么运行关闭回调。避免程序中途退出。因为 # 在_maybe_run_close_callback、_maybe_add_error_listener等方法中都 # 会比较self._pending_callbacks参数值，如果该值不为0，则表示该loop过程 # 还在执行，不能去运行关闭回调。最后的finally块中会递减该值。 self._pending_callbacks += 1 while not self.closed(): # 从socket中读数据，直到得到EWOULDBLOCK（当一个非阻塞的操作没有数据 # 操作时，如读操作时，缓存区空了，此时没有数据读了，写操作时，缓存区已 # 满，无法再写入）或者类似的错误。在Windows上为EWOULDBLOCK，Linux # 上为EAGAIN if self._read_to_buffer() == 0: break self._run_streaming_callback() # 如果已经读完了所有可以使用的字节，就跳出这个循环。不能在 # 这里调用read_from_buffer，因为它与pending_callback和 # error_listener机制的微妙交互。 # 如果已经达到target_bytes，则已经读取完成了。 if (target_bytes is not None and self._read_buffer_size \u003e= target_bytes): break # 否则，需要调用更加昂贵的find_read_pos。 在每次读取时这样做 # 效率不高，所以在第一次读取以及每当读取缓冲区大小加倍时都要这样做。 if self._read_buffer_size \u003e= next_find_pos: pos = self._find_read_pos() if pos is not None: return pos next_find_pos = self._read_buffer_size * 2 return self._find_read_pos() finally: # 递减该属性值，以便能执行关闭回调等操作 self._pending_callbacks -= 1 读取底层 socket fd 中的数据，将其保存到缓存中。通过判断该 socket 连接是否断开进行循环读取操作，最主要的就是 self._read_to_buffer() 方法，封装了对 socket 中读取到的数据处理过程。最终会调用 socket 原生的读取函数 socket.recv(buffer)，即 read_from_fd() 函数，此函数在 IOStream 中被实现。 ","date":"2017-11-06","objectID":"/tornado_iostream/:1:5","tags":["Tornado"],"title":"tornado iostream 实现解析","uri":"/tornado_iostream/"},{"categories":["Tornado 源码解析"],"content":"tornado.iostream.BaseIOStream._read_from_buffer() def _read_from_buffer(self, pos): # 尝试从缓冲区中完成当前正在等待的读取 # 重置参数 self._read_bytes = self._read_delimiter = self._read_regex = None self._read_partial = False self._run_read_callback(pos, False) ","date":"2017-11-06","objectID":"/tornado_iostream/:1:6","tags":["Tornado"],"title":"tornado iostream 实现解析","uri":"/tornado_iostream/"},{"categories":["Tornado 源码解析"],"content":"tornado.iostream.BaseIOStream._run_read_callback() def _run_read_callback(self, size, streaming): # 判断是否要运行stream回调函数，read_until_regex没有该函数 if streaming: callback = self._streaming_callback else: callback = self._read_callback self._read_callback = self._streaming_callback = None # 如果self._read_future不为空 if self._read_future is not None: assert callback is None future = self._read_future self._read_future = None future.set_result(self._consume(size)) if callback is not None: assert (self._read_future is None) or streaming self._run_callback(callback, self._consume(size)) else: # If we scheduled a callback, we will add the error listener # afterwards. If we didn't, we have to do it now. self._maybe_add_error_listener() 首先通过 streaming 参数，决定 callback 是何值。streaming 参数针对 read_bytes、read_until_close 这两个读取方法，而 read_until、read_until_regex 没有 streaming_callback。针对没有 streaming_callback 的方法，会判断 self._read_callback 和 self._read_future，如果 self._read_future 不会空，则会使用 Future 对象将数据返回，否则通过 callback 回调返回。Future 详解参考：tornado_concurrent ","date":"2017-11-06","objectID":"/tornado_iostream/:1:7","tags":["Tornado"],"title":"tornado iostream 实现解析","uri":"/tornado_iostream/"},{"categories":["Tornado 源码解析"],"content":"tornado.iostream.BaseIOStream._consume() def _consume(self, loc): # 消耗缓存区的loc数量数据，并将其返回 if loc == 0: return b\"\" assert loc \u003c= self._read_buffer_size # 获取已读取到缓存区的总数据self._read_buffer，并截取其中从位置 # self._read_buffer_pos（最开始为0）到self._read_buffer_pos + loc # 中的数据 b = (memoryview(self._read_buffer) [self._read_buffer_pos:self._read_buffer_pos + loc] ).tobytes() self._read_buffer_pos += loc self._read_buffer_size -= loc # Amortized O(1) shrink # (this heuristic is implemented natively in Python 3.4+ # but is replicated here for Python 2) if self._read_buffer_pos \u003e self._read_buffer_size: del self._read_buffer[:self._read_buffer_pos] self._read_buffer_pos = 0 return b ","date":"2017-11-06","objectID":"/tornado_iostream/:1:8","tags":["Tornado"],"title":"tornado iostream 实现解析","uri":"/tornado_iostream/"},{"categories":["Tornado 源码解析"],"content":"tornado http1connection 解析 tornado http1connection 主要是对 http 协议进行了封装。 ","date":"2017-11-06","objectID":"/tornado_http1connection/:1:0","tags":["Tornado"],"title":"tornado http1connection 实现解析","uri":"/tornado_http1connection/"},{"categories":["Tornado 源码解析"],"content":"tornado.http1connection.HTTP1ServerConnection.start_serving() def start_serving(self, delegate): # 这里断言delegate是httputil.HTTPServerConnectionDelegate的实例 assert isinstance(delegate, httputil.HTTPServerConnectionDelegate) self._serving_future = self._server_request_loop(delegate) self.stream.io_loop.add_future(self._serving_future, lambda f: f.result()) 开始处理这个连接上的请求，在 tornado.HTTPServer.handle_stream() 中调用此方法，传入的参数为 HTTPServer 的实例，即 delegate 为 HTTPServer 实例，由于 HTTPServer 继承至 httputil.HTTPServerConnectionDelegate，所以断言成功，程序开始执行 self._server_request_loop()。 ","date":"2017-11-06","objectID":"/tornado_http1connection/:1:1","tags":["Tornado"],"title":"tornado http1connection 实现解析","uri":"/tornado_http1connection/"},{"categories":["Tornado 源码解析"],"content":"tornado.http1connection.HTTP1ServerConnection._server_request_loop() @gen.coroutine def _server_request_loop(self, delegate): try: while True: # 初始化HTTP1Connection实例 conn = HTTP1Connection(self.stream, False, self.params, self.context) # 调用delegate的start_request处理连接请求 request_delegate = delegate.start_request(self, conn) try: # 读取http响应 ret = yield conn.read_response(request_delegate) except (iostream.StreamClosedError, iostream.UnsatisfiableReadError): return except _QuietException: # This exception was already logged. conn.close() return except Exception: gen_log.error(\"Uncaught exception\", exc_info=True) conn.close() return # 如果ret为false，则表示读取了完整的http响应 if not ret: return yield gen.moment finally: delegate.on_close(self)v 方法中调用了 delegate.start_request(self, conn)，即 tornado.httpserver.HTTPServer.start_request()，得到一个 httputil.HTTPMessageDelegate 实例，即 request_delegate。接下来开始读取响应数据。 ","date":"2017-11-06","objectID":"/tornado_http1connection/:1:2","tags":["Tornado"],"title":"tornado http1connection 实现解析","uri":"/tornado_http1connection/"},{"categories":["Tornado 源码解析"],"content":"tornado.http1connection.HTTP1Connection.read_response() def read_response(self, delegate): # 判断是否需要解压缩数据 if self.params.decompress: delegate = _GzipMessageDelegate(delegate, self.params.chunk_size) return self._read_message(delegate) ","date":"2017-11-06","objectID":"/tornado_http1connection/:1:3","tags":["Tornado"],"title":"tornado http1connection 实现解析","uri":"/tornado_http1connection/"},{"categories":["Tornado 源码解析"],"content":"tornado.http1connection.HTTP1Connection._read_message() @gen.coroutine def _read_message(self, delegate): need_delegate_close = False try: # 读取请求header数据，返回Future对象 header_future = self.stream.read_until_regex( b\"\\r?\\n\\r?\\n\", max_bytes=self.params.max_header_size) # 判断header_timeout是否为None，如果为None，则直接读取header_future数据 if self.params.header_timeout is None: header_data = yield header_future else: try: # header超时实现 header_data = yield gen.with_timeout( self.stream.io_loop.time() + self.params.header_timeout, header_future, io_loop=self.stream.io_loop, quiet_exceptions=iostream.StreamClosedError) except gen.TimeoutError: self.close() raise gen.Return(False) # 解析header信息，HTTP协议分为request-line、request-header、 # request-body三个部分的。在查看各浏览器、服务器配置的时候往往将 # request-line、request-header归为一类了 start_line, headers = self._parse_headers(header_data) # 判断是否作为客户端 if self.is_client: # 如果作为客户端，则解析服务端响应起始行 start_line = httputil.parse_response_start_line(start_line) self._response_start_line = start_line else: # 如果作为服务端，则解析客户端请求起始行 start_line = httputil.parse_request_start_line(start_line) self._request_start_line = start_line self._request_headers = headers # 判断是否能保持长链接，即Connection: keep_alive self._disconnect_on_finish = not self._can_keep_alive( start_line, headers) need_delegate_close = True with _ExceptionLoggingContext(app_log): header_future = delegate.headers_received(start_line, headers) if header_future is not None: yield header_future if self.stream is None: # We've been detached. need_delegate_close = False raise gen.Return(False) skip_body = False if self.is_client: if (self._request_start_line is not None and self._request_start_line.method == 'HEAD'): skip_body = True code = start_line.code if code == 304: # 304 responses may include the content-length header # but do not actually have a body. # http://tools.ietf.org/html/rfc7230#section-3.3 skip_body = True if code \u003e= 100 and code \u003c 200: # 1xx responses should never indicate the presence of # a body. if ('Content-Length' in headers or 'Transfer-Encoding' in headers): raise httputil.HTTPInputError( \"Response code %d cannot have body\" % code) # TODO: client delegates will get headers_received twice # in the case of a 100-continue. Document or change? yield self._read_message(delegate) else: if (headers.get(\"Expect\") == \"100-continue\" and not self._write_finished): self.stream.write(b\"HTTP/1.1 100 (Continue)\\r\\n\\r\\n\") if not skip_body: body_future = self._read_body( start_line.code if self.is_client else 0, headers, delegate) if body_future is not None: if self._body_timeout is None: yield body_future else: try: yield gen.with_timeout( self.stream.io_loop.time() + self._body_timeout, body_future, self.stream.io_loop, quiet_exceptions=iostream.StreamClosedError) except gen.TimeoutError: gen_log.info(\"Timeout reading body from %s\", self.context) self.stream.close() raise gen.Return(False) self._read_finished = True if not self._write_finished or self.is_client: need_delegate_close = False with _ExceptionLoggingContext(app_log): delegate.finish() # If we're waiting for the application to produce an asynchronous # response, and we're not detached, register a close callback # on the stream (we didn't need one while we were reading) if (not self._finish_future.done() and self.stream is not None and not self.stream.closed()): self.stream.set_close_callback(self._on_connection_close) yield self._finish_future if self.is_client and self._disconnect_on_finish: self.close() if self.stream is None: raise gen.Return(False) except httputil.HTTPInputError as e: gen_log.info(\"Malformed HTTP message from %s: %s\", self.context, e) self.close() raise gen.Return(False) finally: if need_delegate_close: with _ExceptionLoggingContext(app_log): delegate.on_connection_close() header_future = None self._clear_callbacks() raise gen.Return(True) 重要方法，首先会调用 stream 的 read_until_regex 方法开始读取客户端请求传入的头数据（http 协议的header），返回一个 Future 对象，即 header_future，详解参考：tornado_iostream#read_until_regex()；接着会判断是否有设置 header_timeout，而在该方","date":"2017-11-06","objectID":"/tornado_http1connection/:1:4","tags":["Tornado"],"title":"tornado http1connection 实现解析","uri":"/tornado_http1connection/"},{"categories":["Tornado 源码解析"],"content":"tornado netutil 实现解析 ","date":"2017-09-25","objectID":"/tornado_netutil/:1:0","tags":["Tornado"],"title":"tornado netutil 实现解析","uri":"/tornado_netutil/"},{"categories":["Tornado 源码解析"],"content":"tornado.netutil.bind_sockets() 该方法创建绑定到给定端口和地址的监听套接字 socket。返回套接字对象的列表，比如给定的 address 参数映射到多个 IP 地址，则返回多个 socket，最常见的是混合使用 IPv4 与 IPv6，则会创建对应的两个 socket。 def bind_sockets(port, address=None, family=socket.AF_UNSPEC, backlog=_DEFAULT_BACKLOG, flags=None, reuse_port=False): # 当设置了端口复用时，会检查系统是否支持端口复用功能 if reuse_port and not hasattr(socket, \"SO_REUSEPORT\"): raise ValueError(\"the platform doesn't support SO_REUSEPORT\") sockets = [] if address == \"\": address = None # 如果系统不支持IPv6并且参数family为AF_UNSPEC，则family选择IPv4协议 if not socket.has_ipv6 and family == socket.AF_UNSPEC: family = socket.AF_INET if flags is None: flags = socket.AI_PASSIVE bound_port = None # 循环遍历获取的地址信息 for res in set(socket.getaddrinfo(address, port, family, socket.SOCK_STREAM, 0, flags)): af, socktype, proto, canonname, sockaddr = res #　排除另类数据 if (sys.platform == 'darwin' and address == 'localhost' and af == socket.AF_INET6 and sockaddr[3] != 0): continue try: # 创建socket对象 sock = socket.socket(af, socktype, proto) except socket.error as e: if errno_from_exception(e) == errno.EAFNOSUPPORT: continue raise # 设置close-on-exec标志位 set_close_exec(sock.fileno()) # 设置SO_REUSEADDR if os.name != 'nt': sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) #　设置SO_REUSEPORT if reuse_port: sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEPORT, 1) if af == socket.AF_INET6: # 在linux上，ipv6 socket也默认接受ipv4，但是这样就无法绑定到ipv4 # 中的0.0.0.0和ipv6中的::。 # 在其他系统上，单独的套接字必须用于监听ipv4和ipv6。 # 为了保持一致性，请务必在ipv6套接字上禁用ipv4，并在需要时使用 # 单独的ipv4套接字。 # Windows上的Python 2.x没有IPPROTO_IPV6。 if hasattr(socket, \"IPPROTO_IPV6\"): sock.setsockopt(socket.IPPROTO_IPV6, socket.IPV6_V6ONLY, 1) # 当port参数为None时，会自动分配绑定端口，该端口应同时绑定在IPv4和IPv6。 # 当第一次循环时，bound_port会记录系统自动分配的port，然后应用到接下来的循环 host, requested_port = sockaddr[:2] if requested_port == 0 and bound_port is not None: sockaddr = tuple([host, bound_port] + list(sockaddr[2:])) # 设置socket为非阻塞 sock.setblocking(0) # 绑定socket sock.bind(sockaddr) # 记录下本次绑定的端口 bound_port = sock.getsockname()[1] # 开启socket监听 sock.listen(backlog) sockets.append(sock) return sockets 如上基本为 socket 的常规操作，主要操作放在了 IPv4 与 IPv6 的兼容方面。最终返回分别基于 IPv4 与 IPv6 两个 socket 对象组成的 list。 ","date":"2017-09-25","objectID":"/tornado_netutil/:1:1","tags":["Tornado"],"title":"tornado netutil 实现解析","uri":"/tornado_netutil/"},{"categories":["Tornado 源码解析"],"content":"tornado.netutil.add_accept_handler() 正是该方法将 web 服务器与 IOLoop 连接了起来，主要用于添加一个 IOLoop 事件处理器来接受服务器 socket 上的新连接（来自客户端的连接）。当一个客户端连接被 accept，callback 函数将会被调用。 def add_accept_handler(sock, callback, io_loop=None): if io_loop is None: io_loop = IOLoop.current() def accept_handler(fd, events): # 在我们处理回调时可能会有更多的连接; 为了防止其他任务的饥饿（如果该值过大， # 可能会导致程序执行当前队列时间过长，而后续任务无法被执行），我们必须限制 # 我们一次接受的连接数。理想情况下，我们将接受输入此方法时等待的连接数， # 但是此信息不可用（而且在运行任何回调之前重新排列此方法以调用accept() # 多次可能会对多进程配置中的负载平衡产生不利影响）。 相反，我们使用（默认） # listen backlog作为我们可以合理接受的连接数的粗略启发式。 for i in xrange(_DEFAULT_BACKLOG): try: connection, address = sock.accept() except socket.error as e: # _ERRNO_WOULDBLOCK表示我们接受了每个有用的连接 if errno_from_exception(e) in _ERRNO_WOULDBLOCK: return # ECONNABORTED表示有个链接已经被关闭了但任然在接受队列中 if errno_from_exception(e) == errno.ECONNABORTED: continue raise # 调用callback callback(connection, address) # 将服务器端sock以读事件注册到epoll，即epoll一直监听着服务器端socket，只要有 # 客户端连接到服务器端socket，epoll就会触发，epoll.poll()方法就会返回，IOLoop # 就会调用accept_handler方法，最终调用callback(connection, address) io_loop.add_handler(sock, accept_handler, IOLoop.READ) ","date":"2017-09-25","objectID":"/tornado_netutil/:1:2","tags":["Tornado"],"title":"tornado netutil 实现解析","uri":"/tornado_netutil/"},{"categories":["Tornado 源码解析"],"content":"tornado httpserver 详解 tornado httpserver 封装了对 http 请求的处理，是一个非阻塞、单线程的 HTTP 服务器。一个完整的 web 服务器示例如下，启动脚本后在浏览器访问 http://localhost:8888，页面会显示 Hello, world： import tornado.httpserver import tornado.ioloop import tornado.options import tornado.web from tornado.options import define, options define(\"port\", default=8888, help=\"run on the given port\", type=int) class MainHandler(tornado.web.RequestHandler): def get(self): self.write(\"Hello, world\") def main(): # 解析启动命令 tornado.options.parse_command_line() # 创建Application示例 application = tornado.web.Application([ (r\"/\", MainHandler), ]) # 创建HTTPServer实例 http_server = tornado.httpserver.HTTPServer(application) # 监听端口，创建服务器socket http_server.listen(options.port) # 获取IOLoop并启动 tornado.ioloop.IOLoop.current().start() if __name__ == \"__main__\": main() 从实例中可以看到一个 web 服务器同时使用了 tornado.httpserver.HTTPServer 与 tornado.ioloop.IOLoop，二者不可分离。 HTTPServer 有三个父类：tornado.tcpserver.TCPServer、tornado.util.Configurable、 tornado.httputil.HTTPServerConnectionDelegate 当创建 HTTPServer 实例，即调用 tornado.httpserver.HTTPServer(application) 时，程序首先会调用 tornado.util.Configurable.__new__() 方法创建 HTTPServer 实例，对 tornado.util.Configurable 的详解可参考： tornado 配置类 Configurable，实例创建完成之后，会调用 tornado.httpserver.HTTPServer.initialize() 初始化参数配置。 ","date":"2017-09-08","objectID":"/tornado_httpserver/:1:0","tags":["Tornado"],"title":"tornado httpserver 实现解析","uri":"/tornado_httpserver/"},{"categories":["Tornado 源码解析"],"content":"tornado.httpserver.HTTPServer.initialize() def initialize(self, request_callback, no_keep_alive=False, io_loop=None, xheaders=False, ssl_options=None, protocol=None, decompress_request=False, chunk_size=None, max_header_size=None, idle_connection_timeout=None, body_timeout=None, max_body_size=None, max_buffer_size=None, trusted_downstream=None): # 由tornado.util.Configurable分析可知，self.request_callback为 # tornado.web.Application实例 self.request_callback = request_callback self.no_keep_alive = no_keep_alive self.xheaders = xheaders self.protocol = protocol self.conn_params = HTTP1ConnectionParameters( decompress=decompress_request, chunk_size=chunk_size, max_header_size=max_header_size, header_timeout=idle_connection_timeout or 3600, max_body_size=max_body_size, body_timeout=body_timeout, no_keep_alive=no_keep_alive) # 调用TCPServer的初始化方法 TCPServer.__init__(self, io_loop=io_loop, ssl_options=ssl_options, max_buffer_size=max_buffer_size, read_chunk_size=chunk_size) self._connections = set() self.trusted_downstream = trusted_downstream 在开始的示例中实例化 HTTPServer 之后会执行：http_server.listen(options.port)，该代码会创建服务器 socket，监听 8888 端口，socket/tcp 详解可参考： socket/tcp，listen() 方法在 tornado.tcpserver.TCPServer 中实现。 ","date":"2017-09-08","objectID":"/tornado_httpserver/:1:1","tags":["Tornado"],"title":"tornado httpserver 实现解析","uri":"/tornado_httpserver/"},{"categories":["Tornado 源码解析"],"content":"tornado.tcpserver.TCPServer.listen() def listen(self, port, address=\"\"): # 调用bind_sockets sockets = bind_sockets(port, address=address) self.add_sockets(sockets) listen() 方法中就两行代码，分别调用了两个方法：tornado.netutil.bind_sockets()、add_sockets。tornado.netutil.bind_sockets() 详解参考：tornado_netutil#bind_sockets() ","date":"2017-09-08","objectID":"/tornado_httpserver/:1:2","tags":["Tornado"],"title":"tornado httpserver 实现解析","uri":"/tornado_httpserver/"},{"categories":["Tornado 源码解析"],"content":"tornado.tcpserver.TCPServer.add_sockets() def add_sockets(self, sockets): # 获取当前IOLoop对象，此时还没有start if self.io_loop is None: self.io_loop = IOLoop.current() for sock in sockets: # 保存socket到self._sockets self._sockets[sock.fileno()] = sock # 重点方法 add_accept_handler(sock, self._handle_connection, io_loop=self.io_loop) add_sockets() 方法最重要的是调用 add_accept_handler() 函数，详解参考：tornado_netutil#add_accept_handler()，从 add_accept_handler() 函数的详解可知，客户端连接到服务器之后的数据传输，最终调用 self._handle_connection() 方法完成。 ","date":"2017-09-08","objectID":"/tornado_httpserver/:1:3","tags":["Tornado"],"title":"tornado httpserver 实现解析","uri":"/tornado_httpserver/"},{"categories":["Tornado 源码解析"],"content":"tornado.tcpserver.TCPServer._handle_connection() def _handle_connection(self, connection, address): # 对ssl相关处理，可以略过 if self.ssl_options is not None: assert ssl, \"Python 2.6+ and OpenSSL required for SSL\" try: connection = ssl_wrap_socket(connection, self.ssl_options, server_side=True, do_handshake_on_connect=False) except ssl.SSLError as err: if err.args[0] == ssl.SSL_ERROR_EOF: return connection.close() else: raise except socket.error as err: if errno_from_exception(err) in (errno.ECONNABORTED, errno.EINVAL): return connection.close() else: raise try: # 如果是ssl连接，则使用SSLIOStream处理connection，否则使用IOStream if self.ssl_options is not None: stream = SSLIOStream(connection, io_loop=self.io_loop, max_buffer_size=self.max_buffer_size, read_chunk_size=self.read_chunk_size) else: stream = IOStream(connection, io_loop=self.io_loop, max_buffer_size=self.max_buffer_size, read_chunk_size=self.read_chunk_size) # 处理stream future = self.handle_stream(stream, address) if future is not None: # 将future添加到IOLoop self.io_loop.add_future(gen.convert_yielded(future), lambda f: f.result()) except Exception: app_log.error(\"Error in connection callback\", exc_info=True) 以非 ssl 请求为例，tornado 会实例化 tornado.iostream.IOStream 对象，用它去处理流，该对象主要封装了对请求数据读写的一些操作。之后会调用 self.handle_stream(stream, address)，而该方法在 tornado.HTTPServer中被实现。 ","date":"2017-09-08","objectID":"/tornado_httpserver/:1:4","tags":["Tornado"],"title":"tornado httpserver 实现解析","uri":"/tornado_httpserver/"},{"categories":["Tornado 源码解析"],"content":"tornado.httpserver.HTTPServer.handle_stream() def handle_stream(self, stream, address): # 将相关参数保存上下文中，以便之后获取 context = _HTTPRequestContext(stream, address, self.protocol, self.trusted_downstream) # 初始化HTTP1ServerConnection实例 conn = HTTP1ServerConnection( stream, self.conn_params, context) # 保存连接conn到self._connections self._connections.add(conn) # 开始在该conn连接上处理请求 conn.start_serving(self) 该方法主要是完成了对 HTTP1ServerConnection 的初始化，以及通过调用 start_serving 开始处理请求。http1connection.HTTP1ServerConnection.start_serving() 详解参考：tornado_http1connection#start_serving ","date":"2017-09-08","objectID":"/tornado_httpserver/:1:5","tags":["Tornado"],"title":"tornado httpserver 实现解析","uri":"/tornado_httpserver/"},{"categories":["Tornado 源码解析"],"content":"相关方法解析 ","date":"2017-09-08","objectID":"/tornado_httpserver/:2:0","tags":["Tornado"],"title":"tornado httpserver 实现解析","uri":"/tornado_httpserver/"},{"categories":["Tornado 源码解析"],"content":"tornado.httpserver.HTTPServer.start_request() def start_request(self, server_conn, request_conn): if isinstance(self.request_callback, httputil.HTTPServerConnectionDelegate): delegate = self.request_callback.start_request(server_conn, request_conn) else: delegate = _CallableAdapter(self.request_callback, request_conn) if self.xheaders: delegate = _ProxyAdapter(delegate, request_conn) return delegate 方法实现了父类 tornado.httputil.HTTPServerConnectionDelegate 中的 start_request() 方法，当新的请求开始时，这个方法会被服务器调用。 通过上面 tornado.httpserver.HTTPServer.initialize() 详解可知，self.request_callback 为 tornado.web.Application 实例，而 tornado.web.Application 刚好继承至httputil.HTTPServerConnectionDelegate，则会调用 tornado.web.Application 的 start_request() 方法。 最终返回的是继承至 httputil.HTTPMessageDelegate 的 _RoutingDelegate 对象，即 delegate 为 httputil.HTTPMessageDelegate 实例。 ","date":"2017-09-08","objectID":"/tornado_httpserver/:2:1","tags":["Tornado"],"title":"tornado httpserver 实现解析","uri":"/tornado_httpserver/"},{"categories":["Tornado 源码解析"],"content":"tornado posix 实现解析 tornado.platform.posix，Posix 平台特定功能的实现。Posix 平台指“可移植操作系统接口”（Portable Operation System Interface），最后的 x 代表类 Unix 系统。该文件主要是对 Linux 系统相关 API 的实现，Windows NT 系列实现为 tornado.platform.windows、tornado.platform.common。 ","date":"2017-09-01","objectID":"/tornado_platform_posix/:1:0","tags":["Tornado"],"title":"tornado posix 实现解析","uri":"/tornado_platform_posix/"},{"categories":["Tornado 源码解析"],"content":"close-on-exec 标志详解 当我们 fork 子进程时，子进程以写时复制（COW，Copy-On-Write）方式获得父进程的数据空间、堆和栈副本，这其中也包括文件描述符。刚刚 fork 成功时，父子进程中相同的文件描述符指向系统文件表中的同一项（这也意味着他们共享同一文件偏移量）。 接着，在子进程中我们会 exec 另一个程序，此时会用全新的程序替换子进程的正文，数据，堆和栈等。此时保存文件描述符的变量当然也不存在了，我们就无法关闭无用的文件描述符了。所以通常我们会 fork 子进程后在子进程中直接执行 close 关掉无用的文件描述符，然后再执行 exec。 但是在复杂系统中，有时我们 fork 子进程时已经不知道打开了多少个文件描述符（包括 socket 句柄等），这此时进行逐一清理确实有很大难度。我们期望的是能在 fork 子进程前打开某个文件句柄时就指定好：“这个句柄我在 fork 子进程后执行 exec 时就关闭”。其实是有这样的方法的：即所谓的 close-on-exec。设置 close-on-exec 为 FD_CLOEXEC，即 1（系统默认为 0），这样，当 fork 子进程后，仍然可以使用 fd。但执行 exec 后系统就会字段关闭子进程中的 fd 了，即不能再在该文件中读写数据了。 ","date":"2017-09-01","objectID":"/tornado_platform_posix/:1:1","tags":["Tornado"],"title":"tornado posix 实现解析","uri":"/tornado_platform_posix/"},{"categories":["Tornado 源码解析"],"content":"tornado.platform.posix def set_close_exec(fd): # 取得与文件描述符fd联合的close-on-exec标志，类似FD_CLOEXEC。 # 如果返回值和FD_CLOEXEC进行与运算结果是0的话，文件保持交叉式访问exec()， # 否则如果通过exec运行的话，文件将被关闭 flags = fcntl.fcntl(fd, fcntl.F_GETFD) # 设置close-on-exec标志，该标志以参数arg的FD_CLOEXEC位决定， # 很多现存的涉及文件描述符标志的程序并不使用常数 FD_CLOEXEC， # 而是将此标志设置为0(系统默认，在exec时不关闭)或1(在exec时关闭) fcntl.fcntl(fd, fcntl.F_SETFD, flags | fcntl.FD_CLOEXEC) def _set_nonblocking(fd): # 取得fd的文件状态标志 flags = fcntl.fcntl(fd, fcntl.F_GETFL) # 设置fd描述符状态标志为非阻塞，如果read(1024)调用没有可读取的数据， # 或者如果write(1024)操作时写缓存区已满， # 则read或write调用将返回-1和EAGAIN错误，而不会被阻塞 fcntl.fcntl(fd, fcntl.F_SETFL, flags | os.O_NONBLOCK) # 唤醒者（另一线程） class Waker(interface.Waker): def __init__(self): r, w = os.pipe() _set_nonblocking(r) _set_nonblocking(w) set_close_exec(r) set_close_exec(w) self.reader = os.fdopen(r, \"rb\", 0) self.writer = os.fdopen(w, \"wb\", 0) def fileno(self): return self.reader.fileno() def write_fileno(self): return self.writer.fileno() def wake(self): try: self.writer.write(b\"x\") except (IOError, ValueError): pass def consume(self): try: while True: result = self.reader.read() if not result: break except IOError: pass def close(self): self.reader.close() common.try_close(self.writer) 通过上面对 close-on-exec 标志的详解，再解读 tornado.platform.posix 就容易理解了。set_close_exec(fd) 就是为了设置 close-on-exec 标志位为 1；_set_nonblocking(fd) 为了设置 IO 读写为非阻塞模式。 类 Waker 可以解释为唤醒者。它继承至 tornado.platform.interface.Waker，是一个类似 socket（pipe 管道）的对象，可以从 select.select() 或 epoll.poll() 等类似函数唤醒另一个线程。tornado.ioloop.IOLoop 将会把Waker的读文件描述符添加到 select（或 epoll 或 kqueue）中。 由于 epoll.poll()（select.select()）函数是阻塞的，即当没有读写事件发生时会休眠，而当另一个线程想要唤醒 IOLoop 时，它会调用 Waker.wake()，向 pipe 中写入数据，此时，已经被注册到 epoll 中的读管道 pipe 会被触发，从而 epoll.poll() 函数返回，即所谓唤醒了 IOLoop。 IOLoop 一旦醒来，它将调用 Waker.consume() 回调函数，以进行必要的每次唤醒清理，即将为唤醒 IOLoop 而写入的数据读完。当 IOLoop 关闭时，它也关闭了它的 waker。 ","date":"2017-09-01","objectID":"/tornado_platform_posix/:1:2","tags":["Tornado"],"title":"tornado posix 实现解析","uri":"/tornado_platform_posix/"},{"categories":["Tornado 源码解析"],"content":"tornado util configurable 实现解析 tornado.util.Configurable，一个配置类，是工厂模式的实现，通过使用构造函数（__new__()）作为工厂方法。其子类必须实现 configurable_base()、configurable_default()、initialize()。通过调用 configure() 函数去配置当基类（不是指 Configurable，而是继承至 Configurable 的类，如 tornado.ioloop.IOLoop）被实例化时使用的实现类，以及配置其实现类初始化的关键字参数。 示例 from tornado import httpclient httpclient.AsyncHTTPClient.configure (\"tornado.curl_httpclient.CurlAsyncHTTPClient\", max_clients=10000) http_client = httpclient.AsyncHTTPClient() 以 tornado.httpclient.AsyncHTTPClient 为示例来开始 tornado.util.Configurable 的剖析。从 tornado 源码可知，AsyncHTTPClient 继承至 Configurable，同时 tornado.curl_httpclient.CurlAsyncHTTPClient 继承至 AsyncHTTPClient。 第二行 AsyncHTTPClient 调用 configure 去设置它的实现类及关键字参数 max_clients=10000。其源码中直接调用了父类（Configurable）的 configure() 函数。 tornado.httpclient.AsyncHTTPClient.configure() @classmethod def configure(cls, impl, **kwargs): super(AsyncHTTPClient, cls).configure(impl, **kwargs) tornado.util.Configurable.configure() @classmethod def configure(cls, impl, **kwargs): # cls为AsyncHTTPClient，获取可配置层次结构的基类base（AsyncHTTPClient） base = cls.configurable_base() # 由上面的例子得：impl=\"tornado.curl_httpclient.CurlAsyncHTTPClient\" if isinstance(impl, (str, unicode_type)): # 引入tornado.curl_httpclient.CurlAsyncHTTPClient到当前上下文环境 impl = import_object(impl) if impl is not None and not issubclass(impl, cls): raise ValueError(\"Invalid subclass of %s\" % cls) # 通过全局变量保存数据，这两个变量是初始化实例 # （tornado.util.Configurable.__new__()）时非常重要的数据 # 值为：tornado.curl_httpclient.CurlAsyncHTTPClient base.__impl_class = impl # 值为：{\"max_clients\": 10000} base.__impl_kwargs = kwargs 第三行获取 AsyncHTTPClient 实例，将会调用tornado.util.Configurable.__new__()函数。 tornado.util.Configurable.new() def __new__(cls, *args, **kwargs): # cls为AsyncHTTPClient，获取可配置层次结构的基类， # 通常是其自身（如tornado.httpclient.AsyncHTTPClient.configurable_base()） base = cls.configurable_base() init_kwargs = {} # 判断cls是否是基类base if cls is base: # 获取当前配置的实现类，因为之前配置过实现类，即第二行， # 所以得到impl为tornado.curl_httpclient.CurlAsyncHTTPClient impl = cls.configured_class() # 判断configure()函数配置的关键字参数是否为空 if base.__impl_kwargs: # 更新初始化参数字典，因为之前配置过关键字参数，即第二行， # base.__impl_kwargs={\"max_clients\": 10000} init_kwargs.update(base.__impl_kwargs) else: # 实现类即为cls impl = cls # 更新初始化参数字典 init_kwargs.update(kwargs) # 实例化cls，如示例，instance为tornado.curl_httpclient.CurlAsyncHTTPClient instance = super(Configurable, cls).__new__(impl) # 初始化实例参数 instance.initialize(*args, **init_kwargs) return instance tornado.util.Configurable.configured_class() @classmethod def configured_class(cls): # cls为AsyncHTTPClient base = cls.configurable_base() # 判断有没有调用tornado.util.Configurable.configure()函数进行配置， # 如果没有配置过，就调用默认设置configurable_default() if cls.__impl_class is None: base.__impl_class = cls.configurable_default() return base.__impl_class tornado.util.Configurable.configured_class() 函数是选取实现类的关键，它会判断是否调用过 tornado.util.Configurable.configure() 函数去配置实现类了，然后以此选择相应的实现类。 ","date":"2017-08-31","objectID":"/tornado_util_configurable/:1:0","tags":["Tornado"],"title":"tornado util configurable 实现解析","uri":"/tornado_util_configurable/"},{"categories":["Tornado 源码解析"],"content":"tornado ioloop 实现解析 tornado ioloop 是一个基于水平触发的非阻塞 socket 的 IO 事件循环。在 Linux 系统上会使用 epoll，Mac 和 BSD 系统中使用 kqueue，否则使用 select。在分析源码之前需要搞清楚几个知识点： Socket、TCP 详解 IO多路复用（select、epoll、kqueue） ioloop.IOLoop，继承至 tornado.util.Configurable（主要用于子类的创建）。IOLoop 首先会获取一个全局锁，以保证全局只有一个 IOLoop，即单例模式。IOLoop 使用事例： import errno import functools import tornado.ioloop import socket def connection_ready(sock, fd, events): while True: try: connection, address = sock.accept() except socket.error as e: if e.args[0] not in (errno.EWOULDBLOCK, errno.EAGAIN): raise return connection.setblocking(0) handle_connection(connection, address) if __name__ == '__main__': sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM, 0) sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) sock.setblocking(0) sock.bind((\"\", port)) sock.listen(128) # 获取IOLoop对象 io_loop = tornado.ioloop.IOLoop.current() callback = functools.partial(connection_ready, sock) io_loop.add_handler(sock.fileno(), callback, io_loop.READ) # 启动IOLoop io_loop.start() 从事例中知道，使用 ioloop 事件循环，首先需要获取 IOLoop 对象，即调用 tornado.ioloop.IOLoop.current() ","date":"2017-08-25","objectID":"/tornado_ioloop/:1:0","tags":["Tornado"],"title":"tornado ioloop 实现解析","uri":"/tornado_ioloop/"},{"categories":["Tornado 源码解析"],"content":"tornado.ioloop.IOLoop.current() @staticmethod def current(instance=True): current = getattr(IOLoop._current, \"instance\", None) if current is None and instance: return IOLoop.instance() return current 该函数只有四行，它先判断当前线程中是否有 IOLoop 实例正在运行或者被 IOLoop.make_current() 标记过，如果结果为真就直接返回当前 IOLoop，否则调用 IOLoop.instance() 去创建 IOLoop 实例。 ","date":"2017-08-25","objectID":"/tornado_ioloop/:1:1","tags":["Tornado"],"title":"tornado ioloop 实现解析","uri":"/tornado_ioloop/"},{"categories":["Tornado 源码解析"],"content":"tornado.ioloop.IOLoop.instance() @staticmethod def instance(): # 第一层检查 if not hasattr(IOLoop, \"_instance\"): with IOLoop._instance_lock: # 第二层检查 if not hasattr(IOLoop, \"_instance\"): # New instance after double check IOLoop._instance = IOLoop() return IOLoop._instance 在该方法中使用了两次判断，用以实现单例。第一层判断只是为了提升性能，其实只需第二层判断就已经可以实现单例模式。但是如果没有第一层判断，我们只有实例化 IOLoop 的时候需要加锁，其他时候 IOLoop 实例已经存在了，不需要加锁了，但是这时其他需要 IOLoop 实例的线程还是必须等待锁，锁的存在明显降低了效率，有性能损耗。 两层检查都没通过时，会初始化 IOLoop 对象（调用 IOLoop.instance = IOLoop()）。此时，调用 IOLoop 父类 tornado.util.Configurable 的 __new_() 方法实例化 IOLoop 对象。因为没有调用 tornado.util.Configurable.configure() 函数配置实现类，因此 Configurable 会调用 tornado.ioloop.IOLoop.configurable_default() 默认配置实现类（不同系统选择不同的 IO 多路复用机制，即epoll、kqueue、select）。 ","date":"2017-08-25","objectID":"/tornado_ioloop/:1:2","tags":["Tornado"],"title":"tornado ioloop 实现解析","uri":"/tornado_ioloop/"},{"categories":["Tornado 源码解析"],"content":"tornado.ioloop.IOLoop.configurable_default() @classmethod def configurable_default(cls): # 判断系统是否实现epoll，如果有就使用EPollIOLoop作为实现类 if hasattr(select, \"epoll\"): from tornado.platform.epoll import EPollIOLoop return EPollIOLoop # 判断系统是否实现kqueue， 如果有就使用KQueueIOLoop作为实现类 if hasattr(select, \"kqueue\"): # Python 2.6+ on BSD or Mac from tornado.platform.kqueue import KQueueIOLoop return KQueueIOLoop # 否则使用SelectIOLoop作为实现类 from tornado.platform.select import SelectIOLoop return SelectIOLoop 此处我们默认选择 EPollIOLoop 作为实现类。通过 Configurable 会生成 EPollIOLoop 实例，并调用 tornado.platform.epoll.EPollIOLoop.initialize()。 ","date":"2017-08-25","objectID":"/tornado_ioloop/:1:3","tags":["Tornado"],"title":"tornado ioloop 实现解析","uri":"/tornado_ioloop/"},{"categories":["Tornado 源码解析"],"content":"tornado.platform.epoll.EPollIOLoop class EPollIOLoop(PollIOLoop): def initialize(self, **kwargs): # 调用PollIOLoop.initialize() super(EPollIOLoop, self).initialize(impl=select.epoll(), **kwargs) ","date":"2017-08-25","objectID":"/tornado_ioloop/:1:4","tags":["Tornado"],"title":"tornado ioloop 实现解析","uri":"/tornado_ioloop/"},{"categories":["Tornado 源码解析"],"content":"tornado.ioloop.PollIOLoop.initialize() def initialize(self, impl, time_func=None, **kwargs): super(PollIOLoop, self).initialize(**kwargs) self._impl = impl if hasattr(self._impl, 'fileno'): # 设置select.epoll描述符在子进程执行exec()族函数时自动关掉 set_close_exec(self._impl.fileno()) self.time_func = time_func or time.time self._handlers = {} self._events = {} self._callbacks = collections.deque() self._timeouts = [] self._cancellations = 0 self._running = False self._stopped = False self._closing = False self._thread_ident = None self._blocking_signal_threshold = None self._timeout_counter = itertools.count() # 创建一个pipe（管道），当IOLoop处于空闲，即无读写事件时， # 会向该pipe中发送虚假数据从而叫醒IOLoop self._waker = Waker() # 将唤醒者（waker）读文件描述符注册到epoll， # 当另一线程调用tornado.ioloop.PollIOLoop.add_callback()时， # 会调用self._waker.wake()唤醒IOLoop，从而让注册的回调函数运行。 # 由于唤醒正在轮训中的IOLoop比它自动唤醒（超时）消耗资源相对昂贵， # 所以在IOLoop同一线程中不会去主动唤醒它。 self.add_handler(self._waker.fileno(), lambda fd, events: self._waker.consume(), self.READ) 方法中都是进行一些全局数据的初始化工作。其中对 epoll 文件描述符设置 fork 时自动关闭以及叫醒 IOLoop 机制可参考 tornado_platform_posix.md IOLoop 初始化完成之后就会调用 IOLoop.start() 方法去启动 IOLoop，是 IOLoop 的核心。此方法在 PollIOLoop 中实现。 ","date":"2017-08-25","objectID":"/tornado_ioloop/:1:5","tags":["Tornado"],"title":"tornado ioloop 实现解析","uri":"/tornado_ioloop/"},{"categories":["Tornado 源码解析"],"content":"tornado.ioloop.PollIOLoop.start() def start(self): if self._running: raise RuntimeError(\"IOLoop is already running\") self._setup_logging() if self._stopped: self._stopped = False return old_current = getattr(IOLoop._current, \"instance\", None) IOLoop._current.instance = self self._thread_ident = thread.get_ident() self._running = True # signal.set_wakeup_fd解决了事件循环中的条件竞争：select/poll/etc在开始进入 # 中断休眠之前一个信号可能会到达，因此信号可能在没有唤醒select时被处理消耗掉。 # 解决方法与C语言中的同步机制一样，将信号处理程序写入管道，然后通过select获取。 old_wakeup_fd = None if hasattr(signal, 'set_wakeup_fd') and os.name == 'posix': try: # 将唤醒者写管道文件描述符注册为wakeup_fd，当一个信号到来 # 时（如SIGINT，即Ctrl+C），会向其中写入\"\\0\"，从而唤醒select或poll。 # 该函数返回上次设置的文件描述符，如果之前没设置过，则返回-1 old_wakeup_fd = signal.set_wakeup_fd(self._waker.write_fileno()) # 当返回值为-1则说明之前已经设置过wakeup_fd，然后重置 if old_wakeup_fd != -1: signal.set_wakeup_fd(old_wakeup_fd) old_wakeup_fd = None except ValueError: old_wakeup_fd = None try: while True: # 为了避免IO事件饥饿，将新添加的回调延迟到事件循环的下一次迭代中。 # epoll水平触发模式下，当有大量文件描述符就绪需要处理时， # 可能会导致事件太多而没有执行到新添加的回调，这样就会造成IO事件饥饿。 ncallbacks = len(self._callbacks) # timeouts是tornado封装好的超时处理器 due_timeouts = [] # 保存本次迭代需要执行的超时任务 if self._timeouts: now = self.time() while self._timeouts: # 超时事件的回调函数已经被取消，即该超时事件已无效 if self._timeouts[0].callback is None: heapq.heappop(self._timeouts) self._cancellations -= 1 # 当前时间是否已超过超时事件的最后期限，如已超过，则将其取出并 # 保存到due_timeouts，然后执行 elif self._timeouts[0].deadline \u003c= now: due_timeouts.append(heapq.heappop(self._timeouts)) else: break # 优化，当超时事件被取消的次数大于512次并且大于超时事件数量的一 # 半时，清理所有被取消的超时事件 if (self._cancellations \u003e 512 and self._cancellations \u003e (len(self._timeouts) \u003e\u003e 1)): self._cancellations = 0 self._timeouts = [x for x in self._timeouts if x.callback is not None] heapq.heapify(self._timeouts) # 执行所有callback函数，及已经超时的超时事件 for i in range(ncallbacks): self._run_callback(self._callbacks.popleft()) for timeout in due_timeouts: if timeout.callback is not None: self._run_callback(timeout.callback) # 释放资源 due_timeouts = timeout = None # 如果有回调函数，则epoll.poll(timeout)函数的timeout为0 if self._callbacks: poll_timeout = 0.0 # 如果没有回调函数且有超时事件，则poll的timeout为： # 首先获取最近的超时事件的最后期限与当前事件的差值，然后该值与poll的 # timeout的默认值两者取较小值，再与0比较取较大值 elif self._timeouts: poll_timeout = self._timeouts[0].deadline - self.time() poll_timeout = max(0, min(poll_timeout, _POLL_TIMEOUT)) else: poll_timeout = _POLL_TIMEOUT if not self._running: break # 取消信号定时器 if self._blocking_signal_threshold is not None: signal.setitimer(signal.ITIMER_REAL, 0, 0) try: # 整个方法的核心，即epoll.poll(timeout) event_pairs = self._impl.poll(poll_timeout) except Exception as e: if errno_from_exception(e) == errno.EINTR: continue else: raise if self._blocking_signal_threshold is not None: signal.setitimer(signal.ITIMER_REAL, self._blocking_signal_threshold, 0) # 处理IO事件 self._events.update(event_pairs) while self._events: fd, events = self._events.popitem() try: # 通过文件描述符获取在PollIOLoop.add_handler() # 方法中绑定到self._handlers中的socket对象及处理函数 fd_obj, handler_func = self._handlers[fd] # 调用处理器函数 handler_func(fd_obj, events) except (OSError, IOError) as e: if errno_from_exception(e) == errno.EPIPE: pass else: # 如果有异常则调用异常处理函数 self.handle_callback_exception(self._handlers.get(fd)) except Exception: self.handle_callback_exception(self._handlers.get(fd)) # 释放资源 fd_obj = handler_func = None finally: self._stopped = False if self._blocking_signal_threshold is not None: signal.setitimer(signal.ITIMER_REAL, 0, 0) IOLoop._current.instance = old_current if old_wakeup_fd is not None: signal.set_wakeup_fd(old_wakeup_fd) 对 start() 方法中的 timeouts 的详解可以参考 tornado_ioloop_PeriodicCallback.md，其中针对特定实例做了相关分析，能加深理解。callbacks 与 timeouts 的处理是相似的。 tornado IOLoop 中对 epoll.register()、epoll.modify()、epoll.unregister() 分别做了封装，对应 PollIOLoop.add_handler()、PollIOLoop.update_handler()、PollIOLoop.remove_handler()，分别表示注册文件描述符到 epoll 中、更新 epoll 中监听文件描述符的事件类型、删除 epoll 中监听的文件描述符。 ","date":"2017-08-25","objectID":"/tornado_ioloop/:1:6","tags":["Tornado"],"title":"tornado ioloop 实现解析","uri":"/tornado_ioloop/"},{"categories":["Tornado 源码解析"],"content":"IO 多路复用（Reactor） IO 多路复用技术是为实现单线程处理多请求连接，减少系统因频繁的创建线程或进程而产生的资源消耗，这里的复用特指同时使用单一线程。 Linux 下的 select、poll、epoll 为 IO 多路复用的具体实现。当客户端与服务端的 socket 连接建立之后，程序将该 socket 文件描述符注册到 epoll，然后返回，最终交由 epoll 去管理。 epoll 可以同时监听多个文件描述符，当某个或某些文件描述符就绪，则通知程序进行相应的读写操作，否则会一直阻塞直到有文件描述符就绪。我们使用epoll编程时，会设置 socket 非阻塞模式。所以，IO多路复用是同步非阻塞 IO。 ","date":"2017-08-24","objectID":"/io_multiplexing/:1:0","tags":["Tornado","Reactor"],"title":"IO 多路复用（Reactor）","uri":"/io_multiplexing/"},{"categories":["Tornado 源码解析"],"content":"select、poll、epoll 比较 ","date":"2017-08-24","objectID":"/io_multiplexing/:2:0","tags":["Tornado","Reactor"],"title":"IO 多路复用（Reactor）","uri":"/io_multiplexing/"},{"categories":["Tornado 源码解析"],"content":"select 优点 select 目前几乎在所有的平台上支持，其良好跨平台支持也是它的一个优点。 缺点 每次调用 select 都需要把文件描述符（FD）从用户态拷贝到内核，开销比较大 每次都需要在内核遍历所有传入的文件描述符（FD） select 单个进程能够监视的文件描述符的数量存在最大限制，默认是1024，比较小。当然，也可以通过修改宏定义改掉，但这会造成效率的降低。 ","date":"2017-08-24","objectID":"/io_multiplexing/:2:1","tags":["Tornado","Reactor"],"title":"IO 多路复用（Reactor）","uri":"/io_multiplexing/"},{"categories":["Tornado 源码解析"],"content":"poll poll 即轮训，poll 和 select 本质上是一样的，只是描述 fd 集合的方式不同。poll 使用的是 pollfd 结构，select 使用的是 fd_set 结构。 ","date":"2017-08-24","objectID":"/io_multiplexing/:2:2","tags":["Tornado","Reactor"],"title":"IO 多路复用（Reactor）","uri":"/io_multiplexing/"},{"categories":["Tornado 源码解析"],"content":"epoll epoll 是对 select 和 poll 的改进，而且改正了 select、poll 的三个缺点和不足。相对于 select 和 poll 来说，epoll 更加灵活，没有描述符限制。 epoll 使用一个文件描述符管理多个描述符，将用户关系的文件描述符的事件存放到内核的一个事件表中，这样在用户空间和内核空间的 copy 只需一次。 优点 每次注册新事件到 epoll 句柄都会把所有的 fd 拷贝进来，而不是在 epoll_wait 中重复拷贝，这样确保 fd 只会被拷贝一次 epoll 不是像 select/poll 那样每次都把 fd 加入等待队列，epoll 把每个 fd 指定一个回调函数，当设备就绪时，唤醒等待队列的等待者就会调用其它的回调函数，这个回调函数会把就绪的 fd 放入一个就绪链表。epoll_wait 就是在这个就绪链表中查看有没有就绪 fd。 epoll 没有 fd 数目限制 缺点 如果没有大量的 idle-connection 或者 dead-connection，epoll 的效率并不会比 select/poll 高很多，但是当遇到大量的 idle-connection，就会发现 epoll 的效率大大高于 select/poll。 模式 水平触发（level-triggered）：满足状态时触发 当被监控的文件描述符上有可读写事件发生时，epoll_wait() 会通知处理程序去读写。如果这次没有把数据一次性全部读写完(如读写缓冲区太小)，那么下次调用 epoll_wait() 时，它还会通知你在上次没读写完的文件描述符上继续读写，当然如果你一直不去读写，它会一直通知你！！！如果系统中有大量你不需要读写的就绪文件描述符，而它们每次都会返回，这样会大大降低处理程序检索自己关心的就绪文件描述符的效率！！！ 边缘触发（edge-triggered）：状态改变时触发 当被监控的文件描述符上有可读写事件发生时，epoll_wait() 会通知处理程序去读写。如果这次没有把数据全部读写完(如读写缓冲区太小)，那么下次调用 epoll_wait() 时，它不会通知你，也就是它只会通知你一次，直到该文件描述符上出现第二次可读写事件才会通知你去读写余下的数据！！！这种模式比水平触发效率高，系统不会充斥大量你不关心的就绪文件描述符！！！ 例如一个 socket 经过长时间等待后接收到一段 100k 的数据，两种触发方式都会向程序发出就绪通知。假设程序从这个socket 中读取了 50k 数据，并再次调用监听函数，水平触发依然会发出就绪通知，而边缘触发会因为 socket “有数据可读”这个状态没有发生变化而不发出通知且陷入长时间的等待。 ","date":"2017-08-24","objectID":"/io_multiplexing/:2:3","tags":["Tornado","Reactor"],"title":"IO 多路复用（Reactor）","uri":"/io_multiplexing/"},{"categories":["Tornado 源码解析"],"content":"总结 select，poll 实现需要自己不断轮询所有fd集合，直到设备就绪，期间可能要睡眠和唤醒多次交替。而epoll其实也需要调用 epoll_wait 不断轮询就绪链表，期间也可能多次睡眠和唤醒交替，但是它是设备就绪时，调用回调函数，把就绪 fd 放入就绪链表中，并唤醒在 epoll_wait 中进入睡眠的进程。虽然都要睡眠和交替，但是 select 和 poll 在“醒着”的时候要遍历整个 fd 集合，而 epoll 在“醒着”的时候只要判断一下就绪链表是否为空就行了，这节省了大量的 CPU 时间。这就是回调机制带来的性能提升。 select，poll 每次调用都要把 fd 集合从用户态往内核态拷贝一次，并且要把 current 往设备等待队列中挂一次，而epoll 只要一次拷贝，而且把 current 往等待队列上挂也只挂一次（在 epoll_wait 的开始，注意这里的等待队列并不是设备等待队列，只是一个 epoll 内部定义的等待队列）。这也能节省不少的开销。 ","date":"2017-08-24","objectID":"/io_multiplexing/:3:0","tags":["Tornado","Reactor"],"title":"IO 多路复用（Reactor）","uri":"/io_multiplexing/"},{"categories":["Tornado 源码解析"],"content":"Socket socket 是网络进程之间的通讯方式，是对 TCP/IP 协议的封装。socket 并不是像 HTTP、TCP、IP 一样的协议，而是一组调用接口（API）。通过 socket，可以使用 TCP/IP 协议，即可以在网络上传输数据。 http 是应用层协议，web 开发中最常见的协议。当我们在浏览器输入一个网址，比如 http://www.google.com 时: 浏览器首先会去查看本地 hosts 文件，通过域名（google.com）获取其对应的 IP 地址，如果本地没有找到，则继续向上层请求 DNS 服务器，DNS 服务器就像一个树结构，一层一层的向上递进查找。 获取 IP 地址之后，浏览器会根据 IP 与默认端口 80，通过 TCP 协议三次握手与服务器建立 socket 连接。 在 Linux 下，一切皆文件。系统将每一个 socket 连接也抽象成一个文件，客户端与服务器建立连接之后，各自在本地进程中维护一个文件，然后可以向自己文件写入内容供对方读取或者读取对方内容，通讯结束时关闭文件。 ","date":"2017-08-24","objectID":"/socket_tcp/:1:0","tags":["Tornado","Socket","TCP"],"title":"Socket、TCP 详解","uri":"/socket_tcp/"},{"categories":["Tornado 源码解析"],"content":"TCP 三次握手、四次挥手 ","date":"2017-08-24","objectID":"/socket_tcp/:2:0","tags":["Tornado","Socket","TCP"],"title":"Socket、TCP 详解","uri":"/socket_tcp/"},{"categories":["Tornado 源码解析"],"content":"三次握手 第一次握手 客户端尝试连接服务器，向服务器发送 syn 包（同步序列编号 Synchronize Sequence Numbers），syn=j，客户端进入 SYN_SEND 状态等待服务器确认； 第二次握手 服务器接收客户端 syn 包并确认（ack=j+1），同时向客户端发送一个 SYN 包（syn=k），即 SYN+ACK 包，此时服务器进入 SYN_RECV 状态；此时，内核将连接（socket）放入 SYN QUEUE，即 未完成队列 ，该队列大小由 /proc/sys/net/ipv4/tcp_max_syn_backlog 设定； 第三次握手 客户端收到服务器的 SYN+ACK 包，向服务器发送确认包 ACK(ack=k+1），此包发送完毕，客户端和服务器进入 ESTABLISHED状态，完成三次握手。此时，内核将连接（socket）移到 ACCEPT QUEUE，即 已完成队列 ，队列大小为 socket listen(backlog) 函数传入的 backlog 参数与 /proc/sys/net/core/somaxconn 决定，取二者最小值。服务器程序调用 accept 函数后，该连接（socket）被内核从已完成队列移除，并交由服务器程序控制。 注意 : TCP 三次握手在应用程序调用 accept 函数之前由内核完成。调用 accept 只是获取已经完成的连接。 ","date":"2017-08-24","objectID":"/socket_tcp/:2:1","tags":["Tornado","Socket","TCP"],"title":"Socket、TCP 详解","uri":"/socket_tcp/"},{"categories":["Tornado 源码解析"],"content":"四次挥手 第一次挥手 主机1（可以是客户端，也可以是服务器端），设置 Sequence Number 和 Acknowledgment Number，向主机2发送一个 FIN 报文段；此时，主机1进入 FIN_WAIT_1 状态；这表示主机1没有数据要发送给主机2了； 第二次挥手 主机2收到了主机1发送的 FIN 报文段，向主机1回一个 ACK 报文段，Acknowledgment Number 为 Sequence Number 加1；主机1进入 FIN_WAIT_2 状态；主机2告诉主机1，我“同意”你的关闭请求； 第三次挥手 主机2向主机1发送FIN报文段，请求关闭连接，同时主机2进入 LAST_ACK 状态； 第四次挥手 主机1收到主机2发送的 FIN 报文段，向主机2发送 ACK 报文段，然后主机1进入 TIME_WAIT 状态；主机2收到主机1的 ACK 报文段以后，就关闭连接；此时，主机1等待 2MSL 后依然没有收到回复，则证明 Server 端已正常关闭，那么，主机1也可以关闭连接了 ","date":"2017-08-24","objectID":"/socket_tcp/:2:2","tags":["Tornado","Socket","TCP"],"title":"Socket、TCP 详解","uri":"/socket_tcp/"},{"categories":["Tornado 源码解析"],"content":"客户端状态转换过程 ","date":"2017-08-24","objectID":"/socket_tcp/:2:3","tags":["Tornado","Socket","TCP"],"title":"Socket、TCP 详解","uri":"/socket_tcp/"},{"categories":["Tornado 源码解析"],"content":"服务端状态转换过程 ","date":"2017-08-24","objectID":"/socket_tcp/:2:4","tags":["Tornado","Socket","TCP"],"title":"Socket、TCP 详解","uri":"/socket_tcp/"},{"categories":["Tornado 源码解析"],"content":"Socket 编程示例代码 ","date":"2017-08-24","objectID":"/socket_tcp/:3:0","tags":["Tornado","Socket","TCP"],"title":"Socket、TCP 详解","uri":"/socket_tcp/"},{"categories":["Tornado 源码解析"],"content":"server.py import socket import StringIO HOST = \"127.0.0.1\" PORT = 3267 # 创建一个IPV4且基于TCP协议的socket对象 server = socket.socket(socket.AF_INET, socket.SOCK_STREAM) # 绑定监听端口 server.bind((HOST, PORT)) # 开始监听端口，并且等待连接的最大数量为5 server.listen(5) print \"waiting for connection...\" while True: # 接受连接（此方法阻塞） conn, addr = server.accept() print \"Connected by \", addr buffer = StringIO.StringIO() while True: # 每次最多读取1k数据 data = conn.recv(1024) if data: print \"receive client data: \", data buffer.write(data) conn.sendall(\"Hello, {}\".format(data)) else: break print \"receive client ALL datas: \", buffer.getvalue() buffer.close() conn.close() print 'Connection from %s:%s closed.' % addr ","date":"2017-08-24","objectID":"/socket_tcp/:3:1","tags":["Tornado","Socket","TCP"],"title":"Socket、TCP 详解","uri":"/socket_tcp/"},{"categories":["Tornado 源码解析"],"content":"client.py import socket HOST = \"127.0.0.1\" PORT = 3267 # 创建一个IPV4且基于TCP协议的socket对象 client = socket.socket(socket.AF_INET, socket.SOCK_STREAM) # 建立连接 client.connect((HOST, PORT)) while True: try: # 获取用户控制台输入 data = raw_input(\"please input something: \") except: # 关闭客户端连接 client.close() break client.send(data) result = client.recv(1024) print \"client result: \", result ","date":"2017-08-24","objectID":"/socket_tcp/:3:2","tags":["Tornado","Socket","TCP"],"title":"Socket、TCP 详解","uri":"/socket_tcp/"},{"categories":["Tornado 源码解析"],"content":"运行过程 运行 server.py 文件，系统进程会启动一个本地 socket，该 socket 会一直循环等待客户端 socket 的连接。 当我们运行 client.py 文件后，客户端会与服务端建立连接。此时，客户端文件会读取用户在控制台的输入数据，然后发送给服务器。 ","date":"2017-08-24","objectID":"/socket_tcp/:3:3","tags":["Tornado","Socket","TCP"],"title":"Socket、TCP 详解","uri":"/socket_tcp/"},{"categories":["Tornado 源码解析"],"content":"问题 当多开一个控制台再次运行 client.py 时，此时是无法与服务器建立连接的。因为该程序是单线程的，也就是同一时间服务器只能被一个客户端连接。 ","date":"2017-08-24","objectID":"/socket_tcp/:3:4","tags":["Tornado","Socket","TCP"],"title":"Socket、TCP 详解","uri":"/socket_tcp/"},{"categories":["Tornado 源码解析"],"content":"传统解决方法 传统解决方式就是多线程，一个客户端连接开启一个线程去处理。修改后的 server.py 如下： import socket import StringIO import threading HOST = \"127.0.0.1\" PORT = 3267 # 创建一个IPV4且基于TCP协议的socket对象 server = socket.socket(socket.AF_INET, socket.SOCK_STREAM) # 绑定监听端口 server.bind((HOST, PORT)) # 开始监听端口，并且等待连接的最大数量为5 server.listen(5) print \"waiting for connection...\" def handle_conn(conn, addr): buffer = StringIO.StringIO() while True: # 每次最多读取1k数据 data = conn.recv(1024) if data: print \"receive client data: \", data buffer.write(data) conn.sendall(\"Hello, {}\".format(data)) else: break print \"receive client ALL datas: \", buffer.getvalue() buffer.close() conn.close() print 'Connection from %s:%s closed.' % addr while True: # 接受连接（此方法阻塞） conn, addr = server.accept() print \"Connected by \", addr threading.Thread(target=handle_conn, args=(conn, addr)).start() ","date":"2017-08-24","objectID":"/socket_tcp/:3:5","tags":["Tornado","Socket","TCP"],"title":"Socket、TCP 详解","uri":"/socket_tcp/"},{"categories":["Tornado 源码解析"],"content":"优化解决方法 传统解决方法显然不现实，无法承受高并发、高访问量，线程对资源的消耗太大。为解决此问题，引入新概念：IO多路复用（Linux 下 select/poll/epoll），即事件驱动，所谓的 Reactor 模式。它实现了单线程连接多客户端。使用 epoll 实现 server.py： import socket import StringIO import select HOST = \"127.0.0.1\" PORT = 3267 # 创建一个IPV4且基于TCP协议的socket对象 server = socket.socket(socket.AF_INET, socket.SOCK_STREAM) # 绑定监听端口 server.bind((HOST, PORT)) # 开始监听端口，并且等待连接的最大数量为5 server.listen(5) # 设置非阻塞 server.setblocking(0) # 获取epoll对象 epoll = select.epoll() # 向epoll中注册服务器socket描述符，监听读事件 epoll.register(server.fileno(), select.EPOLLIN) print \"waiting for connection...\" connections = {} requests = {} responses = {} while True: # 当监听的socket文件描述符发生改变则会以列表的形式主动报告给用户进程（阻塞） # timeout为获取结果的时间（秒） 当timeout等于-1的时永远等待(默认就是-1)直 # 到文件描述符发生改变，如果指定为1那么epoll每1秒进行汇报一次当前文件描述符 # 的状态哪怕是没有文件描述符发生改变也会返回一个空值 events = epoll.poll(-1) # 循环发生改变的socket，返回的每个对象都是一个元组：(socket描述符, 监听的事件) for fileno, event in events: # 判断是否为服务器socket描述符，如果是则为第一个连接 if fileno == server.fileno(): # 接受连接（此方法阻塞），每一次与客户端建立连接都会创建一个socket，即下面的conn conn, addr = server.accept() print \"Connected by \", addr conn_fd = conn.fileno() # 设置socket连接为非阻塞 conn.setblocking(0) # 将socket连接注册到epoll，监听读事件 epoll.register(conn_fd, select.EPOLLIN) # 保存所有连接 connections[conn_fd] = (conn, addr) # 判断是否为断开事件 elif event \u0026 select.EPOLLHUP: # 解除epoll对socket的监听 epoll.unregister(fileno) # 关闭socket连接 connections[fileno][0].close() del connections[fileno] print 'Connection from %s:%s closed.' % connections[fileno][1] # 判断是否为读事件 elif event \u0026 select.EPOLLIN: conn = connections[fileno][0] buffer = StringIO.StringIO() while True: try: # 每次最多读取1k数据 data = conn.recv(1024) except socket.error, e: # import traceback # print traceback.format_exc() break if data: print \"receive client data: \", data buffer.write(data) conn.sendall(\"Hello, {}\".format(data)) else: break print \"receive client ALL datas: \", buffer.getvalue() requests[fileno] = buffer.getvalue().strip() epoll.modify(fileno, select.EPOLLOUT) buffer.close() # 判断是否为写事件 elif event \u0026 select.EPOLLOUT: connections[fileno].send(requests[fileno]) # 写事件完成之后将该socket从监听写事件改为监听读事件 epoll.modify(fileno, select.EPOLLIN) ","date":"2017-08-24","objectID":"/socket_tcp/:3:6","tags":["Tornado","Socket","TCP"],"title":"Socket、TCP 详解","uri":"/socket_tcp/"},{"categories":["Tornado 源码解析"],"content":"tornado 源码解析 ","date":"2017-08-24","objectID":"/readme/:1:0","tags":["Tornado"],"title":"tornado 源码解析","uri":"/readme/"},{"categories":["Tornado 源码解析"],"content":"简介 此项目主要是针对 python web 框架 — tornado 源码相关模块进行解析，加深对 web 开发的理解。在详解某一模块时会引入相关基础知识概念。包括以下几个知识点： Socket、TCP 详解 IO 多路复用（select、epoll、kqueue） tornado.ioloop 实现解析 tornado posix 实现解析 tornado 配置类 Configurable 实现解析 tornado.httpserver 实现解析 tornado netutil 实现解析 tornado.http1connection 实现解析 tornado.iostream 实现解析 tornado.gen 实现解析 tornado 定时器实现解析 tornado.concurrent 实现解析 tornado 多进程实现解析 ","date":"2017-08-24","objectID":"/readme/:1:1","tags":["Tornado"],"title":"tornado 源码解析","uri":"/readme/"},{"categories":["Tornado 源码解析"],"content":"环境 python 2.7 tornado 4.5.1 Ubuntu 16.04 ","date":"2017-08-24","objectID":"/readme/:1:2","tags":["Tornado"],"title":"tornado 源码解析","uri":"/readme/"}]